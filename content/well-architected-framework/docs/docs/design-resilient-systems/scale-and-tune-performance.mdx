---
page_title: Scale and tune performance
description: Learn how to scale and tune performance.
---

# Scale and tune performance

Scale and performance are critical to fault-tolerant systems, and the interplay between them can complex, complementary, and conflicting relationships For example, the same redundant components which enable fault-tolerance can also support load balancing to improve performance. When you geographically distributed replicas for disaster recovery, they can also support latency reduction goals. You can also benefit from excess production capacity need for fault-tolerance to offer extra performance headroom.

Some examples of conflicting relationships and trade-offs between fault-tolerance and performance include consistency versus performance; stronger consistency guarantees for fault-tolerance often require extra network round trips. Synchronous replication for durability can affect latency, and complex recovery mechanisms can slow down regular operations. Resource overhead for redundancy results in costs which can further improve performance, health checking and monitoring consumer processing and bandwidth, while state synchronization adds network overhead.

Examples of design strategies you can use for scale and performance include:

- **Bulkheads and circuit breakers**: To isolate components so that failures do not cascade, implement back-pressure mechanisms to prevent overload, and design for graceful degradation.
- **Caching and state management**: To improve resilience and performance with local state to reduce network dependency, and cache hierarchies to offer fallback options.
- **Monitoring and adaptation**: To catch potential failures, and inform automatic scaling and recovery systems which respond to overload and failure. Your capacity planning should account for both regular operation and operation in different failure modes.
- **Testing and validation**: Load test and include testing of failure scenarios. Use chaos engineering principles to help understand behavior at scale. Include recovery scenarios in your performance benchmarks.

HashiCorp Consul resources:

- [Operating Consul at Scale](/consul/docs/manage/scale)
- [Enhanced Read Scalability with Read Replicas](/consul/docs/manage/scale/read-replica)
- [Scale Consul DNS](/consul/docs/discover/dns/scale)
- [Monitor Consul server health and performance with metrics and logs](/consul/tutorials/observe-your-network/server-metrics-and-logs)

HashiCorp Nomad resources:

- [Autopilot](/nomad/docs/manage/autopilot)
- [Horizontal cluster autoscaling](/nomad/tutorials/autoscaler/horizontal-cluster-scaling)
- [On-demand batch job cluster autoscaling](/nomad/tutorials/autoscaler/horizontal-cluster-scaling-on-demand-batch)
- [Scale a service](/nomad/tutorials/migrate-monolith/monolith-migration-autoscale)
- [Monitoring Nomad](/nomad/docs/operations/monitoring-nomad)
- [Nomad Autoscaler Telemetry](/nomad/tools/autoscaling/telemetry)

HashiCorp Vault resources:

- [Tune server performance](/vault/tutorials/archive/performance-tuning)
- [Vault telemetry](/vault/docs/internals/telemetry)

HashiCorp resources:

- [React to metrics and monitoring](/well-architected-framework/reliability/reliability-react-to-monitoring)
- [Manage infrastructure and service monitoring](/well-architected-framework/reliability/reliability-deploy-application-monitoring-components)

External resources:

- [What is chaos engineering?](https://www.ibm.com/think/topics/chaos-engineering)
- [Principles of chaos engineering](https://principlesofchaos.org/)
